.. !split

.. _fem:deq:2D:varform:

Variational formulations in 2D and 3D
=====================================

The major difference between deriving variational formulations in 2D and 3D
compared to 1D is the rule for integrating by parts.
The cells have shapes different from an interval, so basis functions
look a bit different, and
there is a technical difference in actually calculating the integrals
over cells. Otherwise, going to 2D and 3D is not a big step from 1D. All
the fundamental ideas still apply.

Integration by parts  (2)
-------------------------

A typical second-order term in a PDE may be written in dimension-independent
notation as

.. math::
         \nabla^2 u \quad\hbox{or}\quad \nabla\cdot\left( {\alpha}(\boldsymbol{x})\nabla u\right)
        {\thinspace .}
        

The explicit forms in a 2D problem become

.. math::
         \nabla^2 u = \nabla\cdot\nabla u =
        \frac{\partial^2 u}{\partial x^2} +
        \frac{\partial^2 u}{\partial y^2},
        

and

.. math::
        
        \nabla\cdot\left( a(\boldsymbol{x})\nabla u\right) =
        \frac{\partial}{\partial x}\left( {\alpha}(x,y)\frac{\partial u}{\partial x}\right) +
        \frac{\partial}{\partial y}\left( {\alpha}(x,y)\frac{\partial u}{\partial y}\right)
        {\thinspace .}
        

We shall continue with the latter operator as the former arises from
just setting :math:`{\alpha} =1`.


.. admonition:: The integration by parts formula for :math:`\int\nabla\cdot({\alpha}\nabla)`

   The general rule for integrating by parts is often referred to as
   `Green's first identity <http://en.wikipedia.org/wiki/Green's_identities>`__:
   
   .. _Eq:fem:deq:2D:int:by:parts:

.. math::
   :label: fem:deq:2D:int:by:parts
           
           -\int_{\Omega} \nabla\cdot ({\alpha}(\boldsymbol{x})\nabla u) v{\, \mathrm{d}x} =
           \int_{\Omega} {\alpha}(\boldsymbol{x})\nabla u\cdot\nabla v {\, \mathrm{d}x} -
           \int_{\partial\Omega} a\frac{\partial u}{\partial n} v {\, \mathrm{d}s},
           
           
   
   where :math:`\partial\Omega` is the boundary of :math:`\Omega` and
   :math:`\partial u/\partial n = \boldsymbol{n}\cdot\nabla u` is the derivative
   of :math:`u` in the outward normal direction, :math:`\boldsymbol{n}` being an outward
   unit normal to :math:`\partial\Omega`. The integrals :math:`\int_\Omega (){\, \mathrm{d}x}` are
   area integrals in 2D and volume integrals in 3D, while
   :math:`\int_{\partial\Omega} (){\, \mathrm{d}s}` is a line integral in 2D and a surface
   integral in 3D.




It will be convenient to divide the boundary into two parts:

 * :math:`\partial\Omega_N`, where we have Neumann conditions
   :math:`-a\frac{\partial u}{\partial n} = g`, and

 * :math:`\partial\Omega_D`, where we have Dirichlet conditions
   :math:`u = u_0`.

The test functions :math:`v` are (as usual) required to vanish on
:math:`\partial\Omega_D`.

Example on a multi-dimensional variational problem
--------------------------------------------------

Here is a quite general, stationary, linear PDE arising in many problems:

.. math::
        
        \boldsymbol{v}\cdot\nabla u + \beta u = \nabla\cdot\left( {\alpha}\nabla u\right) + f,
        \quad\boldsymbol{x}\in\Omega,
        

.. math::
          
        u = u_0,\quad\boldsymbol{x}\in\partial\Omega_D,
        

.. math::
          
        -{\alpha}\frac{\partial u}{\partial n} = g,\quad\boldsymbol{x}\in\partial\Omega_N
        {\thinspace .}
        

The vector field :math:`\boldsymbol{v}` and the scalar functions :math:`a`, :math:`\alpha`, :math:`f`, :math:`u_0`, and
:math:`g` may vary with the spatial coordinate :math:`\boldsymbol{x}` and must be known.

Such a second-order PDE needs exactly one boundary condition at each
point of the boundary, so :math:`\partial\Omega_N\cup\partial\Omega_D`
must be the complete boundary :math:`\partial\Omega`.

Assume that the boundary function :math:`u_0(\boldsymbol{x})` is defined for all :math:`\boldsymbol{x}\in\Omega`.
The unknown function can then be expanded as

.. math::
         u = B + \sum_{j\in{\mathcal{I}_s}} c_j{\psi}_j,\quad B = u_0 {\thinspace .} 

As long as any :math:`{\psi}_j=0` on :math:`\partial\Omega_D`, we realize that :math:`u=u_0`
on :math:`\partial\Omega_D`.

The variational formula is obtained from Galerkin's method, which
technically means multiplying the PDE by a test
function :math:`v` and integrating over :math:`\Omega`:

.. math::
        
        \int_{\Omega} (\boldsymbol{v}\cdot\nabla u + \beta u)v{\, \mathrm{d}x} =
        \int_{\Omega} \nabla\cdot\left( {\alpha}\nabla u\right){\, \mathrm{d}x} + \int_{\Omega}fv {\, \mathrm{d}x}
        {\thinspace .}
        

The second-order term is integrated by parts, according to the formula
:eq:`fem:deq:2D:int:by:parts`:

.. math::
        
        \int_{\Omega} \nabla\cdot\left( {\alpha}\nabla u\right)v {\, \mathrm{d}x} =
        -\int_{\Omega} {\alpha}\nabla u\cdot\nabla v{\, \mathrm{d}x}
        + \int_{\partial\Omega} {\alpha}\frac{\partial u}{\partial n} v{\, \mathrm{d}s}
        {\thinspace .}
        

Galerkin's method therefore leads to

.. math::
        
        \int_{\Omega} (\boldsymbol{v}\cdot\nabla u + \beta u)v{\, \mathrm{d}x} =
        -\int_{\Omega} {\alpha}\nabla u\cdot\nabla v{\, \mathrm{d}x}
        + \int_{\partial\Omega} {\alpha}\frac{\partial u}{\partial n} v{\, \mathrm{d}s}
        + \int_{\Omega} fv {\, \mathrm{d}x}
        {\thinspace .}
        

The boundary term can be developed further by noticing that :math:`v\neq 0`
only on :math:`\partial\Omega_N`,

.. math::
         \int_{\partial\Omega} {\alpha}\frac{\partial u}{\partial n} v{\, \mathrm{d}s}
        = \int_{\partial\Omega_N} {\alpha}\frac{\partial u}{\partial n} v{\, \mathrm{d}s},
        

and that on :math:`\partial\Omega_N`, we have the condition
:math:`a\frac{\partial u}{\partial n}=-g`, so the term becomes

.. math::
        
        -\int_{\partial\Omega_N} gv{\, \mathrm{d}s}{\thinspace .}
        

The final variational form is then

.. math::
        
        \int_{\Omega} (\boldsymbol{v}\cdot\nabla u + \beta u)v{\, \mathrm{d}x} =
        -\int_{\Omega} {\alpha}\nabla u\cdot\nabla v {\, \mathrm{d}x}
        - \int_{\partial\Omega_N} g v{\, \mathrm{d}s}
        + \int_{\Omega} fv {\, \mathrm{d}x}
        {\thinspace .}
        

Instead of using the integral signs, we may use the inner product
notation:

.. math::
        
        (\boldsymbol{v}\cdot\nabla u, v) + (\beta u,v) =
        - ({\alpha}\nabla u,\nabla v) - (g,v)_{N} + (f,v)
        {\thinspace .}
        

The subscript :math:`\,{}_N` in :math:`(g,v)_{N}` is a notation for a line or surface
integral over :math:`\partial\Omega_N`, while :math:`(\cdot,\cdot)` is the area/volume
integral over :math:`\Omega`.

We can derive explicit expressions for the linear system for :math:`\left\{ {c}_j \right\}_{j\in{\mathcal{I}_s}}`
that arises from the variational formulation.
Inserting the :math:`u` expansion results in

.. math::
        
        \sum_{j\in{\mathcal{I}_s}} ((\boldsymbol{v}\cdot\nabla {\psi}_j, {\psi}_i) &+ (\beta {\psi}_j ,{\psi}_i) + ({\alpha}\nabla {\psi}_j,\nabla {\psi}_i))c_j = \\ 
        & (g,{\psi}_i)_{N} + (f,{\psi}_i) -
        (\boldsymbol{v}\cdot\nabla u_0, {\psi}_i) + (\beta u_0 ,{\psi}_i) +
        ({\alpha}\nabla u_0,\nabla {\psi}_i)
        {\thinspace .}
        

This is a linear system with matrix entries

.. math::
        
        A_{i,j} = (\boldsymbol{v}\cdot\nabla {\psi}_j, {\psi}_i) + (\beta {\psi}_j ,{\psi}_i) + ({\alpha}\nabla {\psi}_j,\nabla {\psi}_i)
        

and right-hand side entries

.. math::
        
        b_i = (g,{\psi}_i)_{N} + (f,{\psi}_i) -
        (\boldsymbol{v}\cdot\nabla u_0, {\psi}_i) + (\beta u_0 ,{\psi}_i) +
        ({\alpha}\nabla u_0,\nabla {\psi}_i),
        

for :math:`i,j\in{\mathcal{I}_s}`.

In the finite element method, we usually express :math:`u_0` in terms of
basis functions and restrict :math:`i` and :math:`j` to run over the degrees of
freedom that are not prescribed as Dirichlet conditions.
However, we can also keep all the :math:`\left\{ {c}_j \right\}_{j\in{\mathcal{I}_s}}` as unknowns,
drop the :math:`u_0` in the expansion for :math:`u`, and incorporate all the
known :math:`c_j` values in the linear system. This has been explained
in detail in the 1D case, and the technique is the same for 2D and
3D problems.

Transformation to a reference cell in 2D and 3D
-----------------------------------------------

The real power of the finite element method first becomes evident when
we want to solve partial differential equations posed on two- and
three-dimensional domains of non-trivial geometric shape.  As in 1D,
the domain :math:`\Omega` is divided into :math:`N_e` non-overlapping cells. The
elements have simple shapes: triangles and quadrilaterals are popular
in 2D, while tetrahedra and box-shapes elements dominate in 3D.  The
finite element basis functions :math:`{\varphi}_i` are, as in 1D, polynomials
over each cell.  The integrals in the variational formulation are, as
in 1D, split into contributions from each cell, and these
contributions are calculated by mapping a physical cell, expressed in
physical coordinates :math:`\boldsymbol{x}`, to a reference cell in a local coordinate
system :math:`\boldsymbol{X}`. This mapping will now be explained in detail.

We consider an integral of the type

.. math::
        
        \int_{{\Omega}^{(e)}} {\alpha}(\boldsymbol{x})\nabla{\varphi}_i\cdot\nabla{\varphi}_j{\, \mathrm{d}x},
        

where the :math:`{\varphi}_i` functions are finite element basis functions in
2D or 3D, defined in the physical domain.
Suppose we want to calculate this integral over a reference cell,
denoted by :math:`\tilde\Omega^r`, in a coordinate system with coordinates
:math:`\boldsymbol{X} = (X_0, X_1)` (2D) or :math:`\boldsymbol{X} = (X_0, X_1, X_2)` (3D).
The mapping between a point :math:`\boldsymbol{X}` in the reference coordinate system  and
the corresponding point :math:`\boldsymbol{x}` in the physical coordinate system is
given by a vector relation :math:`\boldsymbol{x}(\boldsymbol{X})`.
The corresponding Jacobian, :math:`J`, of this mapping has entries

.. math::
         J_{i,j}=\frac{\partial x_j}{\partial X_i}{\thinspace .} 

The change of variables requires :math:`{\, \mathrm{d}x}` to be replaced by :math:`\det J{\, \mathrm{d}X}`.
The derivatives in the :math:`\nabla` operator in the variational form are
with respect to :math:`\boldsymbol{x}`, which we may denote by :math:`\nabla_{\boldsymbol{x}}`.
The :math:`{\varphi}_i(\boldsymbol{x})` functions in the integral
are replaced by local basis functions :math:`{\tilde{\varphi}}_r(\boldsymbol{X})` so
the integral features :math:`\nabla_{\boldsymbol{x}}{\tilde{\varphi}}_r(\boldsymbol{X})`. We readily have
:math:`\nabla_{\boldsymbol{X}}{\tilde{\varphi}}_r(\boldsymbol{X})` from formulas for the basis functions in
the reference cell, but
the desired quantity :math:`\nabla_{\boldsymbol{x}}{\tilde{\varphi}}_r(\boldsymbol{X})` requires some efforts
to compute. All the details are provided below.

Let :math:`i=q(e,r)` and consider two space dimensions. By the chain rule,

.. math::
        
        \frac{\partial {\tilde{\varphi}}_r}{\partial X} =
        \frac{\partial {\varphi}_i}{\partial X} =
        \frac{\partial {\varphi}_i}{\partial x}\frac{\partial x}{\partial X} +
        \frac{\partial {\varphi}_i}{\partial y}\frac{\partial y}{\partial X},
        

and

.. math::
        
        \frac{\partial {\tilde{\varphi}}_r}{\partial Y} =
        \frac{\partial {\varphi}_i}{\partial Y} =
        \frac{\partial {\varphi}_i}{\partial x}\frac{\partial x}{\partial Y} +
        \frac{\partial {\varphi}_i}{\partial y}\frac{\partial y}{\partial Y}
        {\thinspace .}
        

We can write these two equations as a vector equation

.. math::
        
        \left[\begin{array}{c}
        \frac{\partial {\tilde{\varphi}}_r}{\partial X}\\ 
        \frac{\partial {\tilde{\varphi}}_r}{\partial Y}
        \end{array}\right]
        =
        \left[\begin{array}{cc}
        \frac{\partial x}{\partial X} & \frac{\partial y}{\partial X}\\ 
        \frac{\partial x}{\partial Y} & \frac{\partial y}{\partial Y}
        \end{array}\right]
        \left[\begin{array}{c}
        \frac{\partial {\varphi}_i}{\partial x}\\ 
        \frac{\partial {\varphi}_i}{\partial y}
        \end{array}\right]
        

Identifying

.. math::
         \nabla_{\boldsymbol{X}}{\tilde{\varphi}}_r = \left[\begin{array}{c}
        \frac{\partial {\tilde{\varphi}}_r}{\partial X}\\ 
        \frac{\partial {\tilde{\varphi}}_r}{\partial Y}
        \end{array}\right],
        \quad
        J =
        \left[\begin{array}{cc}
        \frac{\partial x}{\partial X} & \frac{\partial y}{\partial X}\\ 
        \frac{\partial x}{\partial Y} & \frac{\partial y}{\partial Y}
        \end{array}\right],
        \quad
        \nabla_{\boldsymbol{x}}{\varphi}_r =
        \left[\begin{array}{c}
        \frac{\partial {\varphi}_i}{\partial x}\\ 
        \frac{\partial {\varphi}_i}{\partial y}
        \end{array}\right],
        

we have the relation

.. math::
         \nabla_{\boldsymbol{X}}{\tilde{\varphi}}_r = J\cdot\nabla_{\boldsymbol{x}}{\varphi}_i,

which we can solve with respect to :math:`\nabla_{\boldsymbol{x}}{\varphi}_i`:

.. math::
        
        \nabla_{\boldsymbol{x}}{\varphi}_i = J^{-1}\cdot\nabla_{\boldsymbol{X}}{\tilde{\varphi}}_r{\thinspace .}
        

On the reference cell, :math:`{\varphi}_i(\boldsymbol{x}) = {\tilde{\varphi}}_r(\boldsymbol{X})`, so

.. math::
        
        \nabla_{\boldsymbol{x}}{\tilde{\varphi}}_r(\boldsymbol{X}) = J^{-1}(\boldsymbol{X})\cdot\nabla_{\boldsymbol{X}}{\tilde{\varphi}}_r(\boldsymbol{X}){\thinspace .}
        

This means that we have the following transformation of the
integral in the physical domain to its counterpart over the reference cell:

.. math::
        
        \int_{\Omega}^{(e)} {\alpha}(\boldsymbol{x})\nabla_{\boldsymbol{x}}{\varphi}_i\cdot\nabla_{\boldsymbol{x}}{\varphi}_j{\, \mathrm{d}x}
        \int_{\tilde\Omega^r} {\alpha}(\boldsymbol{x}(\boldsymbol{X}))(J^{-1}\cdot\nabla_{\boldsymbol{X}}{\tilde{\varphi}}_r)\cdot
        (J^{-1}\cdot\nabla{\tilde{\varphi}}_s)\det J{\, \mathrm{d}X}
        

Numerical integration
---------------------

Integrals are normally computed by numerical integration rules.
For multi-dimensional cells, various families of rules exist.
All of them are similar to what is shown in 1D:
:math:`\int f {\, \mathrm{d}x}\approx \sum_jw_if(\boldsymbol{x}_j)`, where :math:`w_j` are weights and
:math:`\boldsymbol{x}_j` are corresponding points.

The file `numint.py <http://tinyurl.com/nm5587k/approx/numint.py>`__ contains the functions
``quadrature_for_triangles(n)`` and ``quadrature_for_tetrahedra(n)``,
which returns lists of points and weights corresponding to integration
rules with ``n`` points over the reference triangle
with vertices :math:`(0,0)`, :math:`(1,0)`, :math:`(0,1)`, and the reference tetrahedron
with vertices :math:`(0,0,0)`, :math:`(1,0,0)`, :math:`(0,1,0)`, :math:`(0,0,1)`,
respectively. For example, the first two rules for integration over
a triangle have 1 and 3 points:

.. code-block:: ipy

        >>> import numint
        >>> x, w = numint.quadrature_for_triangles(num_points=1)
        >>> x
        [(0.3333333333333333, 0.3333333333333333)]
        >>> w
        [0.5]
        >>> x, w = numint.quadrature_for_triangles(num_points=3)
        >>> x
        [(0.16666666666666666, 0.16666666666666666),
         (0.66666666666666666, 0.16666666666666666),
         (0.16666666666666666, 0.66666666666666666)]
        >>> w
        [0.16666666666666666, 0.16666666666666666, 0.16666666666666666]

Rules with 1, 3, 4, and 7 points over the triangle will exactly integrate
polynomials of degree 1, 2, 3, and 4, respectively.
In 3D, rules with 1, 4, 5, and 11 points over the tetrahedron will
exactly integrate polynomials of degree 1, 2, 3, and 4, respectively.

Convenient formulas for P1 elements in 2D
-----------------------------------------

We shall now provide some formulas for piecewise linear :math:`{\varphi}_i` functions
and their integrals *in the physical coordinate system*.
These formulas make it convenient to compute with P1 elements without
the need to work in the reference coordinate system and deal with mappings
and Jacobians.
A lot of computational and algorithmic details are hidden by this approach.

Let :math:`\Omega^{(e)}` be cell number :math:`e`, and let the three vertices
have global vertex numbers :math:`I`, :math:`J`, and :math:`K`.
The corresponding coordinates are
:math:`(x_{I},y_{I})`, :math:`(x_{J},y_{J})`, and :math:`(x_{K},y_{K})`.
The basis function :math:`{\varphi}_I` over :math:`\Omega^{(e)}` have the explicit
formula

.. _Eq:fem:approx:fe:2D:phi:I:

.. math::
   :label: fem:approx:fe:2D:phi:I
        
        {\varphi}_I (x,y) = \frac{1}{2}\Delta \left( \alpha_I + \beta_Ix
        + \gamma_Iy\right),
        
        

where

.. must split align in two because we need an array with & and \\

.. (sphinx, ipynb, pandoc requires splitting of align and & in the

.. array confuses the splitting)

.. _Eq:fem:approx:fe:2D:phi:alpha:I:

.. math::
   :label: fem:approx:fe:2D:phi:alpha:I
        
        \alpha_I = x_{J}y_{K} - x_{K}y_{J},
        
        

.. _Eq:fem:approx:fe:2D:phi:beta:I:

.. math::
   :label: fem:approx:fe:2D:phi:beta:I
          
        \beta_I = y_{J} - y_{K},
        
        

.. _Eq:fem:approx:fe:2D:phi:gamma:I:

.. math::
   :label: fem:approx:fe:2D:phi:gamma:I
          
        \gamma_I = x_{K} - x_{J},
        ,
        

and

.. _Eq:fem:approx:fe:2D:phi:Delta:

.. math::
   :label: fem:approx:fe:2D:phi:Delta
        
        2\Delta = \det\left(\begin{array}{rrr}
        1 & x_{I} & y_{I} \\ 
        1 & x_{J} & y_{J} \\ 
        1 & x_{K} & y_{K} \end{array}\right)
        {\thinspace .}
        
        

The quantity :math:`\Delta` is the area of the cell.

The following formula is often convenient when computing element matrices
and vectors:

.. _Eq:fem:approx:fe:2D:phi:integral:

.. math::
   :label: fem:approx:fe:2D:phi:integral
        
        \int_{\Omega^{(e)}} {\varphi}_I^{p}{\varphi}_J^{q}{\varphi}_K^{r} dx dy =
        {p!q!r!\over (p+q+r+2)!}2\Delta
        
        {\thinspace .}
        

(Note that the :math:`q` in this formula is not to be mixed with the :math:`q(e,r)`
mapping of degrees of freedom.)

As an example, the element matrix entry
:math:`\int_{\Omega^{(e)}} {\varphi}_I{\varphi}_J{\, \mathrm{d}x}`
can be computed by setting
:math:`p=q=1` and :math:`r=0`, when :math:`I\neq J`, yielding :math:`\Delta/12`, and
:math:`p=2` and :math:`q=r=0`, when :math:`I=J`, resulting in :math:`\Delta/6`.
We collect these numbers in a local element matrix:

.. math::
        
        \frac{\Delta}{12}
        \left[\begin{array}{ccc}
        2 & 1 & 1\\ 
        1 & 2 & 1\\ 
        1 & 1 & 2
        \end{array}\right]
        

The common element matrix entry :math:`\int_{\Omega^{(e)}} \nabla{\varphi}_I\cdot\nabla{\varphi}_J{\, \mathrm{d}x}`, arising from a Laplace term :math:`\nabla^2u`, can also easily be
computed by the formulas above. We have

.. math::
         \nabla{\varphi}_I\cdot\nabla{\varphi}_J =
        \frac{\Delta^2}{4}(\beta_I\beta_J + \gamma_I\gamma_J) = \hbox{const},

so that the element matrix entry becomes
:math:`\frac{1}{4}\Delta^3(\beta_I\beta_J + \gamma_I\gamma_J)`.

From an implementational point of view, one will work with local vertex
numbers :math:`r=0,1,2`, parameterize the coefficients in the basis
functions by :math:`r`, and look up vertex coordinates through :math:`q(e,r)`.

Similar formulas exist for integration of P1 elements in 3D.

A glimpse of the mathematical theory of the finite element method
-----------------------------------------------------------------

Almost all books on the finite element method that introduces the
abstract variational problem :math:`a(u,v)=L(v)` spend considerable pages on
deriving error estimates and other properties of the approximate
solution. The machinery with function spaces and bilinear and linear
forms has the great advantage that a very large class of PDE problems
can be analyzed in a unified way.  This feature is often taken as an
advantage of finite element methods over finite difference and volume
methods.  Since there are so many excellent textbooks on the
mathematical properties of finite element methods
[Ref2]_ [Ref3]_ [Ref4]_ [Ref5]_ [Ref6]_, this text
will not repeat the theory, but give a glimpse of typical assumptions
and general results for elliptic PDEs.

**Remark.**
The mathematical theory of finite element methods is primarily
developed for to stationary PDE problems of elliptic nature whose
solutions are smooth. However, such problems can be solved with the
desired accuracy by most numerical methods and pose no difficulties.
Time-dependent problems, on the other hand, easily lead to
non-physical features in the numerical solutions and therefore
requires more care and knowledge by the user.  Our focus on the
accuracy of the finite element method will of this reason be centered
around time-dependent problems, but then we need a different set of
tools for the analysis. These tools are based on converting finite
element equations to finite difference form and studying Fourier wave
components.

Abstract variational forms
~~~~~~~~~~~~~~~~~~~~~~~~~~

To list the main results from the mathematical theory of finite elements,
we consider linear PDEs with an abstract variational form

.. math::
         a(u,v) = L(v)\quad\forall v\in V{\thinspace .}

This is the discretized problem (as usual in this book) where we
seek :math:`u\in V`.
The weak formulation of the corresponding continuous problem,
fulfilled by the exact solution :math:`{u_{\small\mbox{e}}}\in\Vex` is here written as

.. math::
         a({u_{\small\mbox{e}}}, v) = L(v)\quad\forall v\in\Vex{\thinspace .}

The space :math:`V` is finite dimensional (with dimension :math:`N+1`),
while :math:`\Vex` is infinite dimensional.
Normally
The hope is that :math:`u\rightarrow{u_{\small\mbox{e}}}` as :math:`N\rightarrow\infty` and
:math:`V\rightarrow\Vex`.

Example on an abstract variational form and associated spaces
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Consider the problem :math:`-u''(x)=f(x)` on :math:`\Omega=[0,1]`, with :math:`u(0)=0` and
:math:`u'(1)=\beta`. The weak form is

.. math::
         a(u,v) = \int_0^1 u'v'dx,\quad L(v)=\int_0^1fvdx + \beta v(1){\thinspace .}

The space :math:`V` for the approximate solution :math:`u` can be chosen in many
ways as previously described.
The exact solution :math:`{u_{\small\mbox{e}}}` fulfills :math:`a(u,v)=L(v)` for all :math:`v` in :math:`\Vex`,
and to specify what :math:`\Vex` is, we need to introduce *Hilbert spaces*.
The Hilbert
space :math:`L^2(\Omega)` consists of all functions that are square-integrable
on :math:`\Omega`:

.. math::
         L^2(\Omega) = \left\lbrace\int_\Omega v^2dx < \infty\right\rbrace{\thinspace .}

The space :math:`\Vex` is the space of all functions whose first-order
derivative is also square-integrable:

.. math::
         \Vex = H^1_0(\Omega) = \left\lbrace v\in L^2(\Omega)\,\vert\,
        \frac{dv}{dx}\in L^2(\Omega),\hbox{ and }v(0)=0\right\rbrace{\thinspace .}

The requirements of square-integrable zeroth- and first-order derivatives
are motivated from the formula for :math:`a(u,v)` where products of the
first-order derivatives are to be integrated on :math:`\Omega`.

The Sobolev space :math:`H^1_0(\Omega)` has an inner product

.. math::
         (u,v)_{H^1} = \int_\Omega (uv + \frac{du}{dx}\frac{dv}{dx})dx,

and associated norm

.. math::
         ||v||_{H^1} = \sqrt{(v,v)_{H^1}}{\thinspace .}

Assumptions
~~~~~~~~~~~

A set of general results builds on the following
assumptions. Let :math:`\Vex` be an infinite-dimensional inner-product space
such that :math:`{u_{\small\mbox{e}}}\in\Vex`. The space has an associated norm :math:`||v||`
(e.g., :math:`||v||_{H^1}` in the example above with :math:`\Vex=H^1_0(\Omega)`).

1. :math:`L(v)` is linear in its argument.

2. :math:`a(u,v)` is a bilinear in its arguments.

3. :math:`L(v)` is bounded (also called continuous) if there exists a positive
   constant :math:`c_0` such that :math:`|L(v)|\leq c_0||v||` $\forall v\in Vex$.

4. :math:`a(u,v)` is bounded (or continuous) if there exists a positive constant
   :math:`c_1` such that :math:`|a(u,v)|\leq c_1||u|| ||v||\ \forall u,v\in\Vex`.

5. :math:`a(u,v`) is elliptic (or coercive) if there exists a positive
   constant :math:`c_2` such that :math:`a(v,v)\geq c_2||v||^2\ \forall v\in\Vex`.

6. :math:`a(u,v)` is symmetric: :math:`a(u,v)=a(v,u)`.

Based on the above assumptions, which must be verified in each specific
problem, one can derive some general results that are listed below.

Existence and uniqueness
~~~~~~~~~~~~~~~~~~~~~~~~

There exists a unique solution of the problem *find* :math:`{u_{\small\mbox{e}}}\in\Vex`
such that

.. math::
         a({u_{\small\mbox{e}}},v)=L(v)\quad\forall v\in\Vex{\thinspace .}

(This result is known as the Lax-Milgram Theorem.)

Stability
~~~~~~~~~

The solution :math:`{u_{\small\mbox{e}}}\in\Vex` obeys the stability estimate

.. math::
         ||u||\leq \frac{c_0}{c_2}{\thinspace .}

Equivalent minimization problem
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The solution :math:`{u_{\small\mbox{e}}}\in\Vex` also fulfills the minimization problem

.. math::
         \min_{v\in\Vex} F(v),\quad F(v)=\frac{1}{2}a(v,v) - L(v){\thinspace .}

Best approximation principle
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The *energy norm* is defined as

.. math::
         ||v||_a = \sqrt{a(v,v)}{\thinspace .}

The discrete solution :math:`u\in V` is the best approximation in energy norm,

.. math::
         ||{u_{\small\mbox{e}}} -  u||_a \leq ||{u_{\small\mbox{e}}} - v||_a\quad\forall v\in V{\thinspace .}

This is quite remarkable: once we have :math:`V` (i.e., a mesh), the Galerkin
method finds the best approximation in this space.
In the example above, we have :math:`||v||_a=\int_0^1 (v')^2dx`, so
the derivative :math:`u'` is closer to :math:`{u_{\small\mbox{e}}}'` than any other possible
function in :math:`V`:

.. math::
         \int_0^1 ({u_{\small\mbox{e}}}' - u')^2dx \leq \int_0^1(u' - v')dx\quad\forall v\in V{\thinspace .}

Best approximation property in the norm of the space
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

If :math:`||v||` is the norm associated with :math:`\Vex`, we have another
best approximation property:

.. math::
         ||{u_{\small\mbox{e}}} - u||\leq\left(\frac{c_1}{c_2}\right)^{\frac{1}{2}}||{u_{\small\mbox{e}}} - v||\quad\forall v\in\boldsymbol{V}{\thinspace .}

Symmetric, positive definite coefficient matrix
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The discrete problem :math:`a(u,v)=L(v)` $\forall v\in V$ leads to a linear
system :math:`Ac=b`, where the coefficient matrix :math:`A` is symmetric (:math:`A^T=A`)
and positive definite (:math:`x^TAx > 0` for all vectors :math:`x\neq 0`).  One
can then use solution methods that demand less storage and that are
faster and more reliable than solvers for general linear systems. One
is also guaranteed the existence and uniqueness of the discrete
solution :math:`u`.

Equivalent matrix minimization problem
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The solution :math:`c` of the linear system :math:`Ac=b` also solves the minimization
problem :math:`\min_w(\frac{1}{2} w^TAw - b^Tw` in the vector space :math:`\mathbb{R}^{N+1}`.

A priori error estimate for the derivative
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In our sample problem, :math:`-u''=f` on :math:`\Omega=[0,1]`, :math:`u(0)=0`, :math:`u'(1)=\beta`,
one can derive the following error estimate for Lagrange finite element
approximations of degree :math:`s`:

.. math::
        
        \left(\int_0^1 ({u_{\small\mbox{e}}}' - u')^2dx\right)^{\frac{1}{2}}&\leq Ch^s||{u_{\small\mbox{e}}}||_{H^{s+1}},\\ 
        ||{u_{\small\mbox{e}}} - u|| &\leq Ch^2 g({u_{\small\mbox{e}}}),
        

where :math:`||u||_{H^{s+1}}` is a norm that integrates the sum of the square of all
derivatives up to order :math:`s+1`, :math:`g({u_{\small\mbox{e}}})` is the integral of :math:`(u'')^2`,
:math:`C` is a constant, and :math:`h` is the maximum
cell length.
The estimate shows that choosing
elements with higher-degree polynomials (large :math:`s`) requires more
smoothness in :math:`{u_{\small\mbox{e}}}` since higher-order derivatives need to be square-integrable.

A consequence of the error estimate is that :math:`u'\rightarrow {u_{\small\mbox{e}}}'`
as :math:`h\rightarrow 0`, i.e., the approximate solution converges to
the exact one.

The constant :math:`C` in this and the next estimate depends on the shape
of triangles in 2D and tetrahedra in 3D: squeezed elements with a
small angle lead to a large :math:`C`, and such deformed elements are
not favorable for the accuracy.

One can generalize the above estimate to the general problem class
:math:`a(u,v)=L(v)`: the error in the derivative is proportional
to :math:`h^s`. Note that the expression :math:`||{u_{\small\mbox{e}}} - u||` in the example
is :math:`||{u_{\small\mbox{e}}} - u||_{H^1}` so it involves the sum of the zeroth and
first derivative. The appearance of the derivative makes the error
proportional to :math:`h^s` - if we only look at the solution it
converges as :math:`h^{s+1}` (see below).

The above estimate is called an *a priori* estimate because the bound
contains the exact solution, which is not computable. There are also
*a posteriori* estimates where the bound involves the approximation
:math:`u`, which is available in computations.

A priori error estimate for the solution
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The finite element solution of our sample problem, using P1 elements, fulfills

.. math::
        
        \left(\int_0^1 ({u_{\small\mbox{e}}} - u)^2dx\right)^{\frac{1}{2}} \leq Ch^2 g({u_{\small\mbox{e}}}){\thinspace .}
        

This estimate shows that the error converges as :math:`h^2` for P1 elements.
An equivalent finite difference method, see the section :ref:`fem:deq:1D:fdm_vs_fem`, is known to have an error proportional to :math:`h^2`, so the above estimate
is expected.
In general, the convergence is :math:`h^{s+1}` for elements with polynomials
of degree :math:`s`. Note that the estimate for :math:`u'` is proportional to
:math:`h` raised to one power less.

