<!--
Automatically generated HTML file from DocOnce source
(https://github.com/hplgit/doconce/)
-->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="DocOnce: https://github.com/hplgit/doconce/" />
<meta name="description" content="Approximation of functions">
<meta name="keywords" content="approximation of vectors in the plane,basis vector,norm,least squreas method vectors,Galerkin method vectors,projection vectors,approximation of general vectors,Galerkin method vectors,projection vectors,approximation of functions,Galerkin method functions,projection functions,approximation by sines,collocation method (approximation),approximation collocation,interpolation,approximation interpolation,Lagrange (interpolating) polynomial,Kronecker delta,Runge's phenomenon,Chebyshev nodes,finite element mesh,mesh finite elements,internal node,shared node,Kronecker delta,chapeau function,hat function,finite element basis function,linear elements,quadratic elements,P1 element,P2 element,element matrix,assembly,affine mapping,mapping of reference cells affine mapping,sparse matrices,mass matrix,mass lumping,lumped mass matrix,cell,vertex,degree of freedom,reference cell,finite element, definition,dof map,finite element expansion reference element,Hermite polynomials,numerical integration Midpoint rule,numerical integration Trapezoidal rule,numerical integration Simpson's rule,numerical integration Newton-Cotes formulas,Midpoint rule,Trapezoidal rule,Simpson's rule,Newton-Cotes rules,Gauss-Legendre quadrature,tensor product,simplex elements,simplices,faces,edges,affine mapping,isoparametric mapping,mapping of reference cells isoparametric mapping">

<title>Approximation of functions</title>

<!-- Bootstrap style: bootswatch_journal -->
<link href="http://netdna.bootstrapcdn.com/bootswatch/3.1.1/journal/bootstrap.min.css" rel="stylesheet">
<!-- not necessary
<link href="http://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
-->

<style type="text/css">
/* Let inline verbatim have the same color as the surroundings */
code { color: inherit; background-color: transparent; }
</style>


</head>

<!-- tocinfo
{'highest level': 1,
 'sections': [('Approximation of vectors',
               1,
               'fem:approx:vec',
               'fem:approx:vec'),
              ('Approximation of planar vectors',
               2,
               'fem:approx:vec:plane',
               'fem:approx:vec:plane'),
              ('The least squares method', 3, None, '___sec2'),
              ('The projection method', 3, None, '___sec3'),
              ('Approximation of general vectors',
               2,
               'fem:approx:vec:Np1dim',
               'fem:approx:vec:Np1dim'),
              ('The least squares method', 3, None, '___sec5'),
              ('The Galerkin or projection method', 3, None, '___sec6'),
              ('Approximation of functions',
               1,
               'fem:approx:global',
               'fem:approx:global'),
              ('The least squares method',
               2,
               'fem:approx:LS',
               'fem:approx:LS'),
              ('The projection (or Galerkin) method', 2, None, '___sec9'),
              ('Example: linear approximation',
               2,
               'fem:approx:global:linear',
               'fem:approx:global:linear'),
              ('Implementation of the least squares method',
               2,
               'fem:approx:global:LS:code',
               'fem:approx:global:LS:code'),
              ('Symbolic integration', 3, None, '___sec12'),
              ('Fall back on numerical integration', 3, None, '___sec13'),
              ('Plotting the approximation', 3, None, '___sec14'),
              ('Perfect approximation',
               2,
               'fem:approx:global:exact',
               'fem:approx:global:exact'),
              ('Ill-conditioning',
               2,
               'fem:approx:global:illconditioning',
               'fem:approx:global:illconditioning'),
              ('Fourier series',
               2,
               'fem:approx:global:Fourier',
               'fem:approx:global:Fourier'),
              ('Orthogonal basis functions',
               2,
               'fem:approx:global:orth',
               'fem:approx:global:orth'),
              ('Numerical computations', 2, None, '___sec19'),
              ('The interpolation (or collocation) method',
               2,
               'fem:approx:global:interp',
               'fem:approx:global:interp'),
              ('Example', 3, None, '___sec21'),
              ('Lagrange polynomials',
               2,
               'fem:approx:global:Lagrange',
               'fem:approx:global:Lagrange'),
              ('Approximation of a polynomial', 3, None, '___sec23'),
              ('Successful example', 3, None, '___sec24'),
              ('Less successful example', 3, None, '___sec25'),
              ('Remedy for strong oscillations', 3, None, '___sec26'),
              ('Finite element basis functions',
               1,
               'fem:approx:fe',
               'fem:approx:fe'),
              ('Elements and nodes',
               2,
               'fem:approx:fe:def:elements:nodes',
               'fem:approx:fe:def:elements:nodes'),
              ('Example', 3, None, '___sec29'),
              ('The basis functions', 2, None, '___sec30'),
              ('Construction principles', 3, None, '___sec31'),
              ('Properties of $\\basphi_i$', 3, None, '___sec32'),
              ('Example on piecewise quadratic finite element functions',
               2,
               None,
               '___sec33'),
              ('Example on piecewise linear finite element functions',
               2,
               None,
               '___sec34'),
              ('Example on piecewise cubic finite element basis functions',
               2,
               None,
               '___sec35'),
              ('Calculating the linear system',
               2,
               'fem:approx:global:linearsystem',
               'fem:approx:global:linearsystem'),
              ('Calculating specific matrix entries', 3, None, '___sec37'),
              ('Calculating a general row in the matrix',
               3,
               None,
               '___sec38'),
              ('Assembly of elementwise computations',
               2,
               'fem:approx:fe:elementwise',
               'fem:approx:fe:elementwise'),
              ('The element matrix', 3, None, '___sec40'),
              ('Assembly of element matrices', 3, None, '___sec41'),
              ('Assembly of irregularly numbered elements and nodes',
               3,
               None,
               '___sec42'),
              ('The element vector', 3, None, '___sec43'),
              ('Mapping to a reference element',
               2,
               'fem:approx:fe:mapping',
               'fem:approx:fe:mapping'),
              ('The coordinate transformation', 3, None, '___sec45'),
              ('Formulas for the element matrix and vector entries',
               3,
               None,
               '___sec46'),
              ('Formulas for local basis functions', 3, None, '___sec47'),
              ('Example: Integration over a reference element',
               2,
               'fem:approx:fe:intg:ref',
               'fem:approx:fe:intg:ref'),
              ('Implementation',
               1,
               'fem:approx:fe:impl',
               'fem:approx:fe:impl'),
              ('Integration',
               2,
               'fem:approx:fe:impl:intg',
               'fem:approx:fe:impl:intg'),
              ('Linear system assembly and solution',
               2,
               'fem:approx:fe:impl:linsys',
               'fem:approx:fe:impl:linsys'),
              ('Example on computing symbolic approximations',
               2,
               'fem:approx:fe:impl:ex1:symbolic',
               'fem:approx:fe:impl:ex1:symbolic'),
              ('Using interpolation instead of least squares',
               2,
               'fem:approx:fe:impl:ex1:collocation',
               'fem:approx:fe:impl:ex1:collocation'),
              ('Example on computing numerical approximations',
               2,
               'fem:approx:fe:impl:ex1:numeric',
               'fem:approx:fe:impl:ex1:numeric'),
              ('The structure of the coefficient matrix',
               2,
               'fem:approx:fe:A:structure',
               'fem:approx:fe:A:structure'),
              ('Applications',
               2,
               'fem:approx:fe:impl:ex2',
               'fem:approx:fe:impl:ex2'),
              ('Sparse matrix storage and solution',
               2,
               'fem:approx:fe:impl:sparse',
               'fem:approx:fe:impl:sparse'),
              ('Comparison of finite element and finite difference approximations',
               1,
               'fem:approx:fe:fd',
               'fem:approx:fe:fd'),
              ('Finite difference approximation of given functions',
               2,
               'fem:approx:fe:fd:fdproj',
               'fem:approx:fe:fd:fdproj'),
              ('Finite difference interpretation of a finite element approximation',
               2,
               'fem:approx:fe:fd:feproj',
               'fem:approx:fe:fd:feproj'),
              ('Making finite elements behave as finite differences',
               2,
               None,
               '___sec61'),
              ('Computations in physical space', 3, None, '___sec62'),
              ('Elementwise computations', 3, None, '___sec63'),
              ('Terminology', 3, None, '___sec64'),
              ('A generalized element concept',
               1,
               'fem:approx:fe:element',
               'fem:approx:fe:element'),
              ('Cells, vertices, and degrees of freedom',
               2,
               'fem:approx:fe:element:terminology',
               'fem:approx:fe:element:terminology'),
              ('Extended finite element concept',
               2,
               'fem:approx:fe:element:def',
               'fem:approx:fe:element:def'),
              ('Implementation',
               2,
               'fem:approx:fe:element:impl',
               'fem:approx:fe:element:impl'),
              ('Computing the error of the approximation',
               2,
               'fem:approx:fe:error',
               'fem:approx:fe:error'),
              ('Example: Cubic Hermite polynomials',
               2,
               'fem:approx:fe:element:impl:Hermite',
               'fem:approx:fe:element:impl:Hermite'),
              ('Numerical integration', 1, None, '___sec71'),
              ('Newton-Cotes rules',
               2,
               'fem:approx:fe:numint1',
               'fem:approx:fe:numint1'),
              ('Gauss-Legendre rules with optimized points',
               2,
               None,
               '___sec73'),
              ('Approximation of functions in 2D',
               1,
               'fem:approx:2D',
               'fem:approx:2D'),
              ('2D basis functions as tensor products of 1D functions',
               2,
               'fem:approx:2D:global',
               'fem:approx:2D:global'),
              ('Example: Polynomial basis in 2D', 2, None, '___sec76'),
              ('Implementation',
               2,
               'fem:approx:2D:global:code',
               'fem:approx:2D:global:code'),
              ('Extension to 3D',
               2,
               'fem:approx:3D:global',
               'fem:approx:3D:global'),
              ('Finite elements in 2D and 3D', 1, None, '___sec79'),
              ('Basis functions over triangles in the physical domain',
               2,
               None,
               '___sec80'),
              ('Element matrices and vectors', 3, None, '___sec81'),
              ('Basis functions over triangles in the reference cell',
               2,
               None,
               '___sec82'),
              ('Affine mapping of the reference cell', 2, None, '___sec83'),
              ('Isoparametric mapping of the reference cell',
               2,
               None,
               '___sec84'),
              ('Computing integrals', 2, None, '___sec85'),
              ('Exercises', 1, None, '___sec86'),
              ('Exercise 1: Linear algebra refresher I',
               2,
               'fem:approx:exer:linalg1',
               'fem:approx:exer:linalg1'),
              ('Exercise 2: Linear algebra refresher II',
               2,
               'fem:approx:exer:linalg2',
               'fem:approx:exer:linalg2'),
              ('Exercise 3: Approximate a three-dimensional vector in a plane',
               2,
               'fem:approx:exer:vec:3Dby2D',
               'fem:approx:exer:vec:3Dby2D'),
              ('Exercise 4: Approximate the exponential function by power functions',
               2,
               'fem:approx:exer:exp:powers',
               'fem:approx:exer:exp:powers'),
              ('Exercise 5: Approximate the sine function by power functions',
               2,
               'fem:approx:exer:sin:powers',
               'fem:approx:exer:sin:powers'),
              ('Exercise 6: Approximate a steep function by sines',
               2,
               'fem:approx:exer:tanh:sine1',
               'fem:approx:exer:tanh:sine1'),
              ('Remarks', 3, None, '___sec93'),
              ('Exercise 7: Approximate a steep function by sines with boundary adjustment',
               2,
               'fem:approx:exer:tanh:sine3',
               'fem:approx:exer:tanh:sine3'),
              ('Remarks', 3, None, '___sec95'),
              ('Exercise 8: Fourier series as a least squares approximation',
               2,
               'fem:approx:exer:Fourier',
               'fem:approx:exer:Fourier'),
              ('Exercise 9: Approximate a steep function by Lagrange polynomials',
               2,
               'fem:approx:exer:tanh:Lagrange',
               'fem:approx:exer:tanh:Lagrange'),
              ('Exercise 10: Define nodes and elements',
               2,
               'fem:approx:fe:exer:mesh1',
               'fem:approx:fe:exer:mesh1'),
              ('Exercise 11: Define vertices, cells, and dof maps',
               2,
               'fem:approx:fe:exer:mesh2',
               'fem:approx:fe:exer:mesh2'),
              ('Exercise 12: Construct matrix sparsity patterns',
               2,
               'fem:approx:fe:exer:defmesh:sparsity',
               'fem:approx:fe:exer:defmesh:sparsity'),
              ('Exercise 13: Perform symbolic finite element computations',
               2,
               'fem:approx:fe:exer:Asinwt:symbolic',
               'fem:approx:fe:exer:Asinwt:symbolic'),
              ('Exercise 14: Approximate a steep function by P1 and P2 elements',
               2,
               'fem:approx:exer:tanh:P1P2',
               'fem:approx:exer:tanh:P1P2'),
              ('Exercise 15: Approximate a steep function by P3 and P4 elements',
               2,
               'fem:approx:exer:tanh:P3P4',
               'fem:approx:exer:tanh:P3P4'),
              ('Exercise 16: Investigate the approximation error in finite elements',
               2,
               'fem:approx:fe:exer:Asinwt:interpol:error',
               'fem:approx:fe:exer:Asinwt:interpol:error'),
              ('Exercise 17: Approximate a step function by finite elements',
               2,
               'fem:approx:fe:exer:Heaviside',
               'fem:approx:fe:exer:Heaviside'),
              ('Exercise 18: 2D approximation with orthogonal functions',
               2,
               'fem:approx:fe:exer:2Dsines:symbolic',
               'fem:approx:fe:exer:2Dsines:symbolic'),
              ('Exercise 19: Use the Trapezoidal rule and P1 elements',
               2,
               'fem:approx:fe:exer:1D:trapez',
               'fem:approx:fe:exer:1D:trapez'),
              ('Problem 20: Compare P1 elements and interpolation',
               2,
               'fem:approx:fe:exer:1D:P1:vs:interp',
               'fem:approx:fe:exer:1D:P1:vs:interp'),
              ('Exercise 21: Implement 3D computations with global basis functions',
               2,
               'fem:approx:fe:exer:3D:approx3D',
               'fem:approx:fe:exer:3D:approx3D'),
              ("Exercise 22: Use Simpson's rule and P2 elements",
               2,
               'fem:approx:fe:exer:1D:simpson',
               'fem:approx:fe:exer:1D:simpson'),
              ('Bibliography', 1, None, '___sec111')]}
end of tocinfo -->

<body>



<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: {
     equationNumbers: {  autoNumber: "none"  },
     extensions: ["AMSmath.js", "AMSsymbols.js", "autobold.js", "color.js"]
  }
});
</script>
<script type="text/javascript"
 src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<!-- newcommands_keep.tex -->
$$
\newcommand{\half}{\frac{1}{2}}
\newcommand{\halfi}{{1/2}}
\newcommand{\tp}{\thinspace .}
\newcommand{\x}{\boldsymbol{x}}
\newcommand{\X}{\boldsymbol{X}}
\renewcommand{\u}{\boldsymbol{u}}
\renewcommand{\v}{\boldsymbol{v}}
\newcommand{\w}{\boldsymbol{w}}
\newcommand{\e}{\boldsymbol{e}}
\newcommand{\f}{\boldsymbol{f}}
\newcommand{\Ix}{\mathcal{I}_x}
\newcommand{\Iy}{\mathcal{I}_y}
\newcommand{\Iz}{\mathcal{I}_z}
\newcommand{\If}{\mathcal{I}_s}     % for FEM
\newcommand{\Ifd}{{I_d}}  % for FEM
\newcommand{\sequencei}[1]{\left\{ {#1}_i \right\}_{i\in\If}}
\newcommand{\basphi}{\varphi}
\newcommand{\baspsi}{\psi}
\newcommand{\refphi}{\tilde\basphi}
\newcommand{\psib}{\boldsymbol{\psi}}
\newcommand{\xno}[1]{x_{#1}}
\newcommand{\Xno}[1]{X_{(#1)}}
\newcommand{\xdno}[1]{\boldsymbol{x}_{#1}}
\newcommand{\dX}{\, \mathrm{d}X}
\newcommand{\dx}{\, \mathrm{d}x}
\newcommand{\Real}{\mathbb{R}}
\newcommand{\Integer}{\mathbb{Z}}
$$




    
<!-- Bootstrap navigation bar -->
<div class="navbar navbar-default navbar-fixed-top">
  <div class="navbar-header">
    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
    <a class="navbar-brand" href="approx.html">Approximation of functions</a>
  </div>
  <div class="navbar-collapse collapse navbar-responsive-collapse">
    <ul class="nav navbar-nav navbar-right">
      <li class="dropdown">
        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contents <b class="caret"></b></a>
        <ul class="dropdown-menu">
     <!-- navigation toc: --> <li><a href="#fem:approx:vec" style="font-size: 80%;">Approximation of vectors</a></li>
     <!-- navigation toc: --> <li><a href="._approx003.html#fem:approx:global" style="font-size: 80%;">Approximation of functions</a></li>
     <!-- navigation toc: --> <li><a href="._approx004.html#fem:approx:fe" style="font-size: 80%;">Finite element basis functions</a></li>
     <!-- navigation toc: --> <li><a href="._approx005.html#fem:approx:fe:impl" style="font-size: 80%;">Implementation</a></li>
     <!-- navigation toc: --> <li><a href="._approx006.html#fem:approx:fe:fd" style="font-size: 80%;">Comparison of finite element and finite difference approximations</a></li>
     <!-- navigation toc: --> <li><a href="._approx007.html#fem:approx:fe:element" style="font-size: 80%;">A generalized element concept</a></li>
     <!-- navigation toc: --> <li><a href="._approx008.html#___sec71" style="font-size: 80%;">Numerical integration</a></li>
     <!-- navigation toc: --> <li><a href="._approx009.html#fem:approx:2D" style="font-size: 80%;">Approximation of functions in 2D</a></li>
     <!-- navigation toc: --> <li><a href="._approx010.html#___sec79" style="font-size: 80%;">Finite elements in 2D and 3D</a></li>
     <!-- navigation toc: --> <li><a href="._approx011.html#___sec86" style="font-size: 80%;">Exercises</a></li>
     <!-- navigation toc: --> <li><a href="._approx012.html#___sec111" style="font-size: 80%;">Bibliography</a></li>

        </ul>
      </li>
    </ul>
  </div>
</div>
</div> <!-- end of navigation bar -->

<div class="container">

<p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p> <!-- add vertical space -->

<a name="part0002"></a>
<!-- !split -->

<h1 id="fem:approx:vec">Approximation of vectors</h1>

<p>
We shall start with introducing two fundamental methods for
determining the coefficients \( c_i \) in <a href="._approx001.html#mjx-eqn-1">(1)</a>. These methods
will be introduce for
approximation of vectors. Using vectors in vector
spaces to bring across the ideas is believed to appear more intuitive
to the reader than starting directly with functions in function spaces.
The extension from vectors to functions will be trivial as soon as
the fundamental ideas are understood.

<p>
The first method of approximation is called the <em>least squares method</em>
and consists in finding \( c_i \) such that the difference \( f-u \), measured
in a certain norm, is minimized. That is, we aim at finding the best
approximation \( u \) to \( f \), with the given norm as measure of &quot;distance&quot;.
The second method is not
as intuitive: we find \( u \) such that the error \( f-u \) is orthogonal to
the space where \( u \) lies. This is known as <em>projection</em>, or
in the context of differential equations, the idea is
also well known as <em>Galerkin's method</em>.
When approximating vectors and functions, the two methods are
equivalent, but this is no longer the case when applying the
principles to differential equations.

<h2 id="fem:approx:vec:plane">Approximation of planar vectors</h2>

<p>
Let \( \f = (3,5) \) be a vector in the \( xy \) plane and suppose
we want to approximate this vector by a vector aligned
in the direction of another vector that is restricted to be aligned
with some vector \( (a,b) \). Figure <a href="#fem:approx:vec:plane:fig">1</a>
depicts the situation. This is the simplest approximation problem
for vectors. Nevertheless, for many readers it will be
wise to refresh some basic linear algebra by consulting a
textbook.  <a href="._approx011.html#fem:approx:exer:linalg1">Exercise 1: Linear algebra refresher I</a> and
<a href="._approx011.html#fem:approx:exer:linalg2">Exercise 2: Linear algebra refresher II</a> suggest specific tasks to regain
familiarity with fundamental operations on inner product vector
spaces. Familiarity with such operations are assumed in the forthcoming
text.

<p>
<center> <!-- figure -->
<hr class="figure">
<center><p class="caption">Figure 1:  Approximation of a two-dimensional vector in a one-dimensional vector space. <div id="fem:approx:vec:plane:fig"></div> </p></center>
<p><img src="fig-approx/vecapprox_plane.png" align="bottom" width=400></p>
</center>

<p>
We introduce the vector space \( V \)
spanned by the vector \( \psib_0=(a,b) \):

$$
\begin{equation}
V = \mbox{span}\,\{ \psib_0\}\tp  \end{equation}
$$

We say that \( \psib_0 \) is a <em>basis vector</em> in the space \( V \).
Our aim is to find the vector \( \u = c_0\psib_0\in V \) which best approximates
the given vector \( \f = (3,5) \). A reasonable criterion for a best
approximation could be to minimize the length of the difference between
the approximate \( \u \) and the given \( \f \). The difference, or error
\( \e = \f -\u \), has its length given by the <em>norm</em>

$$
\begin{equation*} ||\e|| = (\e,\e)^{\half},\end{equation*}
$$

where \( (\e,\e) \) is the <em>inner product</em> of \( \e \) and itself. The inner
product, also called <em>scalar product</em> or <em>dot product</em>, of two vectors
\( \u=(u_0,u_1) \) and \( \v =(v_0,v_1) \) is defined as

$$
\begin{equation}
(\u, \v) = u_0v_0 + u_1v_1\tp  \end{equation}
$$

<p>
<b>Remark.</b>
We should point out that we use the notation
\( (\cdot,\cdot) \) for two different things: \( (a,b) \) for scalar
quantities \( a \) and \( b \) means the vector starting in the origin and
ending in the point \( (a,b) \), while \( (\u,\v) \) with vectors \( \u \) and
\( \v \) means the inner product of these vectors.  Since vectors are here
written in boldface font there should be no confusion.  We may add
that the norm associated with this inner product is the usual
Euclidean length of a vector.

<h3 id="___sec2">The least squares method </h3>

<p>
We now want to find \( c_0 \) such that it minimizes \( ||\e|| \). The algebra
is simplified if we minimize the square of the norm, \( ||\e||^2 = (\e, \e) \),
instead of the norm itself.
Define the function

$$
\begin{equation}
E(c_0) = (\e,\e) = (\f - c_0\psib_0, \f - c_0\psib_0)
\tp
\end{equation}
$$

We can rewrite the expressions of the right-hand side in a more
convenient form for further work:

$$
\begin{equation}
E(c_0) = (\f,\f) - 2c_0(\f,\psib_0) + c_0^2(\psib_0,\psib_0)\tp
\tag{2}
\end{equation}
$$

This rewrite results from using the following fundamental rules for inner
product spaces:

$$
\begin{equation}
(\alpha\u,\v)=\alpha(\u,\v),\quad \alpha\in\Real,
\tag{3}
\end{equation}
$$


$$
\begin{equation}
(\u +\v,\w) = (\u,\w) + (\v, \w),
\tag{4}
\end{equation}
$$


$$
\begin{equation}
(\u, \v) = (\v, \u)\tp  \end{equation}
\tag{5}
$$

<p>
Minimizing \( E(c_0) \) implies finding \( c_0 \) such that

$$
\begin{equation*} \frac{\partial E}{\partial c_0} = 0\tp  \end{equation*}
$$

It turns out that \( E \) has one unique minimum and no maximum point.
Now, when differentiating <a href="#mjx-eqn-2">(2)</a> with respect to \( c_0 \), note
that none of the inner product expressions depend on \( c_0 \), so we simply get

$$
\begin{equation}
\frac{\partial E}{\partial c_0} = -2(\f,\psib_0) + 2c_0 (\psib_0,\psib_0)
\tp
\tag{6}
\end{equation}
$$

Setting the above expression equal to zero and solving for \( c_0 \) gives

$$
\begin{equation}
c_0 = \frac{(\f,\psib_0)}{(\psib_0,\psib_0)},
\tag{7}
\end{equation}
$$

which in the present case, with \( \psib_0=(a,b) \), results in

$$
\begin{equation}
c_0 = \frac{3a + 5b}{a^2 + b^2}\tp  \end{equation}
$$

<p>
For later, it is worth mentioning that setting
the key equation <a href="#mjx-eqn-6">(6)</a> to zero and ordering
the terms lead to

$$
(\f-c0\psib_0,\psib_0) = 0,
$$

or

$$
\begin{equation}
(\e, \psib_0) = 0
\tp
\tag{8}
\end{equation}
$$

This implication of minimizing \( E \) is an important result that we shall
make much use of.

<h3 id="___sec3">The projection method </h3>

<p>
We shall now show that minimizing \( ||\e||^2 \) implies that \( \e \) is
orthogonal to <em>any</em> vector \( \v \) in the space \( V \). This result is
visually quite clear from Figure <a href="#fem:approx:vec:plane:fig">1</a> (think of
other vectors along the line \( (a,b) \): all of them will lead to
a larger distance between the approximation and \( \f \)).
The see mathematically that \( \e \) is orthogonal to any vector \( \v \)
in the space \( V \), we
express any \( \v\in V \) as \( \v=s\psib_0 \) for any scalar parameter \( s \)
(recall that two vectors are orthogonal when their inner product vanishes).
Then we calculate the inner product
$$
\begin{align*}
(\e, s\psib_0) &= (\f - c_0\psib_0, s\psib_0)\\ 
&= (\f,s\psib_0) - (c_0\psib_0, s\psib_0)\\ 
&= s(\f,\psib_0) - sc_0(\psib_0, \psib_0)\\ 
&= s(\f,\psib_0) - s\frac{(\f,\psib_0)}{(\psib_0,\psib_0)}(\psib_0,\psib_0)\\ 
&= s\left( (\f,\psib_0) - (\f,\psib_0)\right)\\ 
&=0\tp
\end{align*}
$$

Therefore, instead of minimizing the square of the norm, we could
demand that \( \e \) is orthogonal to any vector in \( V \), which in our present
simple case amounts to a single vector only.
This method is known as <em>projection</em>.
(The approach can also be referred to as a Galerkin method as
explained at the end of the section <a href="#fem:approx:vec:Np1dim">Approximation of general vectors</a>.)

<p>
Mathematically, the projection method is stated
by the equation

$$
\begin{equation}
(\e, \v) = 0,\quad\forall\v\in V\tp
\tag{9}
\end{equation}
$$

An arbitrary \( \v\in V \) can be expressed as
\( s\psib_0 \), \( s\in\Real \), and therefore
<a href="#mjx-eqn-9">(9)</a> implies

$$
\begin{equation*} (\e,s\psib_0) = s(\e, \psib_0) = 0,\end{equation*}
$$

which means that the error must be orthogonal to the basis vector in
the space \( V \):

$$
\begin{equation*}
(\e, \psib_0)=0\quad\hbox{or}\quad
(\f - c_0\psib_0, \psib_0)=0,
\end{equation*}
$$

which is what we found in <a href="#mjx-eqn-8">(8)</a> from
the least squares computations.

<h2 id="fem:approx:vec:Np1dim">Approximation of general vectors</h2>

<p>
Let us generalize the vector approximation from the previous section
to vectors in spaces with arbitrary dimension. Given some vector \( \f \),
we want to find the best approximation to this vector in
the space

$$
\begin{equation*}
V = \hbox{span}\,\{\psib_0,\ldots,\psib_N\}
\tp
\end{equation*}
$$

We assume that the space has dimension \( N+1 \) and
that <em>basis vectors</em> \( \psib_0,\ldots,\psib_N \) are
linearly independent so that none of them are redundant.
Any vector \( \u\in V \) can then be written as a linear combination
of the basis vectors, i.e.,

$$
\begin{equation*} \u = \sum_{j=0}^N c_j\psib_j,\end{equation*}
$$

where \( c_j\in\Real \) are scalar coefficients to be determined.

<h3 id="___sec5">The least squares method </h3>

<p>
Now we want to find \( c_0,\ldots,c_N \), such that \( \u \) is the best
approximation to \( \f \) in the sense that the distance (error)
\( \e = \f - \u \) is minimized. Again, we define
the squared distance as a function of the free parameters
\( c_0,\ldots,c_N \),

$$
\begin{align}
E(c_0,\ldots,c_N) &= (\e,\e) = (\f -\sum_jc_j\psib_j,\f -\sum_jc_j\psib_j)
\nonumber\\ 
&= (\f,\f) - 2\sum_{j=0}^N c_j(\f,\psib_j) +
\sum_{p=0}^N\sum_{q=0}^N c_pc_q(\psib_p,\psib_q)\tp
\tag{10}
\end{align}
$$

Minimizing this \( E \) with respect to the independent variables
\( c_0,\ldots,c_N \) is obtained by requiring

$$
\begin{equation*}
\frac{\partial E}{\partial c_i} = 0,\quad i=0,\ldots,N
\tp
\end{equation*}
$$

The first term in <a href="#mjx-eqn-10">(10)</a> is independent of \( c_i \), so its
derivative vanishes.
The second term in <a href="#mjx-eqn-10">(10)</a> is differentiated as follows:

$$
\begin{equation}
\frac{\partial}{\partial c_i}
2\sum_{j=0}^N c_j(\f,\psib_j) = 2(\f,\psib_i),
\end{equation}
$$

since the expression to be differentiated is a sum and only one term,
\( c_i(\f,\psib_i) \),
contains \( c_i \) (this term is linear in \( c_i \)).
To understand this differentiation in detail,
write out the sum specifically for,
e.g, \( N=3 \) and \( i=1 \).

<p>
The last term in <a href="#mjx-eqn-10">(10)</a>
is more tedious to differentiate. It can be wise to write out the
double sum for \( N=1 \) and perform differentiation with respect to
\( c_0 \) and \( c_1 \) to see the structure of the expression. Thereafter,
one can generalize to an arbitrary \( N \) and observe that

$$
\begin{align}
\frac{\partial}{\partial c_i}
c_pc_q =
\left\lbrace\begin{array}{ll}
0, & \hbox{ if } p\neq i\hbox{ and } q\neq i,\\ 
c_q, & \hbox{ if } p=i\hbox{ and } q\neq i,\\ 
c_p, & \hbox{ if } p\neq i\hbox{ and } q=i,\\ 
2c_i, & \hbox{ if } p=q= i\tp\\ 
\end{array}\right.
\end{align}
$$

Then

$$
\begin{equation*} \frac{\partial}{\partial c_i}
\sum_{p=0}^N\sum_{q=0}^N c_pc_q(\psib_p,\psib_q)
= \sum_{p=0, p\neq i}^N c_p(\psib_p,\psib_i)
+ \sum_{q=0, q\neq i}^N c_q(\psib_i,\psib_q)
+2c_i(\psib_i,\psib_i)\tp  \end{equation*}
$$

Since each of the two sums is missing the term \( c_i(\psib_i,\psib_i) \),
we may split the very last term in two, to get exactly that &quot;missing&quot;
term for each sum. This idea allows us to write

$$
\begin{equation}
\frac{\partial}{\partial c_i}
\sum_{p=0}^N\sum_{q=0}^N c_pc_q(\psib_p,\psib_q)
= 2\sum_{j=0}^N c_i(\psib_j,\psib_i)\tp
\end{equation}
$$

It then follows that setting

$$
\begin{equation*}
\frac{\partial E}{\partial c_i} = 0,\quad i=0,\ldots,N,\end{equation*}
$$

implies

$$ - 2(\f,\psib_i) + 2\sum_{j=0}^N c_i(\psib_j,\psib_i) = 0,\quad i=0,\ldots,N\tp$$

Moving the first term to the right-hand side shows that the equation is
actually a <em>linear system</em> for the unknown parameters \( c_0,\ldots,c_N \):

$$
\begin{equation}
\sum_{j=0}^N A_{i,j} c_j = b_i, \quad i=0,\ldots,N,
\tag{11}
\end{equation}
$$

where

$$
\begin{align}
A_{i,j} &= (\psib_i,\psib_j),\\ 
b_i &= (\psib_i, \f)\tp  \end{align}
$$

We have changed the order of the two vectors in the inner
product according to <a href="#mjx-eqn-5">(5)</a>:

$$ A_{i,j} = (\psib_j,\psib_i) = (\psib_i,\psib_j),$$

simply because the sequence \( i \)-$j$ looks more aesthetic.

<h3 id="___sec6">The Galerkin or projection method </h3>

<p>
In analogy with the &quot;one-dimensional&quot; example in
the section <a href="#fem:approx:vec:plane">Approximation of planar vectors</a>, it holds also here in the general
case that minimizing the distance
(error) \( \e \) is equivalent to demanding that \( \e \) is orthogonal to
all \( \v\in V \):

$$
\begin{equation}
(\e,\v)=0,\quad \forall\v\in V\tp
\tag{12}
\end{equation}
$$

Since any \( \v\in V \) can be written as \( \v =\sum_{i=0}^N c_i\psib_i \),
the statement <a href="#mjx-eqn-12">(12)</a> is equivalent to
saying that

$$
\begin{equation*} (\e, \sum_{i=0}^N c_i\psib_i) = 0,\end{equation*}
$$

for any choice of coefficients \( c_0,\ldots,c_N \).
The latter equation can be rewritten as

$$
\begin{equation*} \sum_{i=0}^N c_i (\e,\psib_i) =0\tp  \end{equation*}
$$

If this is to hold for arbitrary values of \( c_0,\ldots,c_N \)
we must require that each term in the sum vanishes, which means that

$$
\begin{equation}
(\e,\psib_i)=0,\quad i=0,\ldots,N\tp
\tag{13}
\end{equation}
$$

These \( N+1 \) equations result in the same linear system as
<a href="#mjx-eqn-11">(11)</a>:

$$ (\f - \sum_{j=0}^N c_j\psib_j, \psib_i) = (\f, \psib_i) - \sum_{j=0}^N
(\psib_i,\psib_j)c_j = 0,$$

and hence

$$ \sum_{j=0}^N (\psib_i,\psib_j)c_j = (\f, \psib_i),\quad i=0,\ldots, N
\tp
$$

So, instead of differentiating the
\( E(c_0,\ldots,c_N) \) function, we could simply use
<a href="#mjx-eqn-12">(12)</a> as the principle for
determining \( c_0,\ldots,c_N \), resulting in the \( N+1 \)
equations <a href="#mjx-eqn-13">(13)</a>.

<p>
The names <em>least squares method</em> or <em>least squares approximation</em>
are natural since the calculations consists of
minimizing \( ||\e||^2 \), and \( ||\e||^2 \) is a sum of squares
of differences between the components in \( \f \) and \( \u \).
We find \( \u \) such that this sum of squares is minimized.

<p>
The principle <a href="#mjx-eqn-12">(12)</a>,
or the equivalent form <a href="#mjx-eqn-13">(13)</a>,
is known as <em>projection</em>. Almost the same mathematical idea
was used by the Russian mathematician <a href="http://en.wikipedia.org/wiki/Boris_Galerkin" target="_self">Boris Galerkin</a> to solve
differential equations, resulting in what is widely known as
<em>Galerkin's method</em>.

<p>
<p>
<!-- navigation buttons at the bottom of the page -->
<ul class="pager">
  <li class="previous">
    <a href="._approx001.html">&larr; Prev</a>
  </li>
  <li class="next">
    <a href="._approx003.html">Next &rarr;</a>
  </li>
</ul>
<!-- ------------------- end of main content --------------- -->

</div>  <!-- end container -->
<!-- include javascript, jQuery *first* -->
<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="http://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>

<!-- Bootstrap footer
<footer>
<a href="http://..."><img width="250" align=right src="http://..."></a>
</footer>
-->


</body>
</html>
    

